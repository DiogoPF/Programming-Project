{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EUCTRegister Scaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%run \"C:\\Users\\Diogo\\OneDrive - NOVAIMS\\My Functions\\TG_message.py\"\n",
    "\n",
    "url = \"https://www.clinicaltrialsregister.eu/\"\n",
    "s = HTMLSession()\n",
    "page = s.get(url+ 'ctr-search/search?query=&page=')\n",
    "last_page_num = max([int(a.split('=')[-1]) for a in page.html.links if 'page' in a]) \n",
    "s.close()\n",
    "segment_size = 40\n",
    "\n",
    "'''\n",
    "Trough trial and error we found that the site was ending the connection after roughly 50 trials had been scraped\n",
    "so we decided to do it in batches, restarting the connection each batch.\n",
    "'''\n",
    "\n",
    "try:\n",
    "    for segment_start in range(0, last_page_num, segment_size):\n",
    "        # create a new session for each segment\n",
    "        s = HTMLSession()\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        segment_end = min(segment_start + segment_size, last_page_num)\n",
    "\n",
    "        for page_num in range(segment_start, segment_end):\n",
    "            page = s.get(url+ f'ctr-search/search?query=&page={page_num}')\n",
    "            studies_links = [link for link in page.html.links if link.startswith('/ctr-search/trial') and 'results' not in link]\n",
    "\n",
    "            for study_link in studies_links:\n",
    "                study = s.get(url+ study_link)\n",
    "                #Study Summary\n",
    "                sum_field = study.html.find('td.cellGrey')                                      #All summary fields\n",
    "                sum_field_value = study.html.find('td.cellLighterGrey')                         #All summary values\n",
    "                study_info= {x.text:y.text for x,y in zip(sum_field,sum_field_value)} \n",
    "\n",
    "                #Study Details\n",
    "                details = study.html.find('tr.tricell')                                         # List of all the other field and values (objects)\n",
    "                for detail in details:\n",
    "                    detail_list = detail.text.split('\\n')                                       # Get text of all objects and split to get a list for each filed,value\n",
    "                    if len(detail_list) < 3:\n",
    "                        detail_list.append('')                                                  # Add blanks for fields without values \n",
    "                    study_info[detail_list[1]] = ' '. join(detail_list[2:])                   # Creates dict with Filed and Value(some fields have multiple values, must clean later if needed)\n",
    "\n",
    "                df = df.append(study_info, ignore_index=True)\n",
    "\n",
    "            # save the DataFrame every 40 pages\n",
    "            if page_num % segment_size == 0 or page_num == segment_end - 1:\n",
    "                file_name = fr\"C:\\Users\\Diogo\\OneDrive - NOVAIMS\\PG - EDSA\\3.PfDS - Programing for Data Science\\Group Project\\Group Project\\Rep\\Programming-Project\\EU_data\\EUCTRegister_{segment_start}-{page_num}.csv\"\n",
    "                df.to_csv(file_name, index=False)\n",
    "                df = pd.DataFrame()  # reset the DataFrame to empty\n",
    "\n",
    "        s.close()  # close the session after each segment\n",
    "    message('Success!')\n",
    "\n",
    "except:\n",
    "    message('ERROR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging all files into a single csv\n",
    "\n",
    "folder = r\"C:\\Users\\Diogo\\OneDrive - NOVAIMS\\PG - EDSA\\3.PfDS - Programing for Data Science\\Group Project\\Group Project\\Rep\\Programming-Project\\EU_data\"\n",
    "df_list = []\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    df = pd.read_csv(filepath, low_memory=False)\n",
    "    df_list.append(df)\n",
    "\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "df.to_csv('EuCTRegister.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
